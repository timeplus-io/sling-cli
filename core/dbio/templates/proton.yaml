core:
  drop_table: drop stream if exists {table}
  drop_view: drop view if exists {view}
  create_schema: create database {schema}
  create_table: create stream {table} ({col_types}) {partition_by}
  rename_table: ALTER stream {table} RENAME TO {new_table}
  alter_columns: alter stream {table} modify column {col_ddl}
  modify_column: "{column} {type}"
  update: alter stream {table} update {set_fields} where {pk_fields_equal}
  insert_from_table: insert into {tgt_table} ({tgt_fields}) select {src_fields} from table({src_table})
  incremental_select: select {fields} from table({table}) where {incremental_where_cond} order by {update_key} asc

metadata:
  current_database: select current_database()

  databases: |
    select current_database() as name

  # Timeplus does not have schemas
  # has database and table, for example: database1.table1
  # for our purpose a schema is a database
  schemas: |
    select name as schema_name
    from system.databases
    order by name

  tables: |
    select database as schema_name, name as table_name, 'false' as is_view
    from system.tables
    where engine not in ('View','MaterializedView')
      {{if .schema -}} and database = '{schema}' {{- end}}
    order by database, name

  views: |
    select database as schema_name, name as table_name, 'true' as is_view
    from system.tables
    where engine in ('View','MaterializedView')
      {{if .schema -}} and database = '{schema}' {{- end}}
    order by database, name

  columns: |
    select name as column_name, type as data_type
    from system.columns
    where database = '{schema}'
      and table = '{table}'
    order by position

  primary_keys: |
    select 1

  indexes: |
    select 1

  columns_full: |
    with tables as (
      select
        database,
        name as table_name,
        engine in ('View','MaterializedView') as is_view
      from system.tables
      where database = '{schema}' and name = '{table}'
    )
    select
      cols.database as schema_name,
      cols.table as table_name,
      cols.name as column_name,
      cols.type as data_type,
      cols.position as position
    from system.columns as cols
    join tables
      on tables.database = cols.database
      and tables.table_name = cols.table
    order by cols.database, cols.table, cols.position

  schemata: |
    with tables as (
      select
        database,
        name as table_name,
        engine in ('View','MaterializedView') as is_view
      from system.tables
      where 1=1
        {{if .schema -}} and database = '{schema}' {{- end}}
        {{if .tables -}} and name in ({tables}) {{- end}}
    )
    select
      cols.database as schema_name,
      cols.table as table_name,
      tables.is_view as is_view,
      cols.name as column_name,
      cols.type as data_type,
      cols.position as position
    from system.columns as cols
    join tables
      on tables.database = cols.database
      and tables.table_name = cols.table
    order by cols.database, cols.table, cols.position

  ddl_table: SHOW CREATE STREAM `{schema}`.`{table}`

  ddl_view: |
    SHOW CREATE VIEW `{schema}`.`{table}`

  sessions: select *
    from pg_stat_activity
    where state = 'active'

  session_terminate: select pg_terminate_backend({pid})

analysis:
  field_chars: |
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field, sum(case when cast({field} as text) ~ '\n' then 1 else 0 end) as cnt_nline,
      sum(case when cast({field} as text) ~ '\t' then 1 else 0 end) as cnt_tab,
      sum(case when cast({field} as text) ~ ',' then 1 else 0 end) as cnt_comma,
      sum(case when cast({field} as text) ~ '"' then 1 else 0 end) as cnt_dquote,
      min(char_length(cast({field} as text))) as f_min_len,
      max(char_length(cast({field} as text))) as f_max_len
    from `{schema}`.`{table}`

  field_stat_len: |
    -- field_stat_len {table}
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field,
      '{type}' as type,
      count(*) as tot_cnt,
      min(char_length({field})) as f_min_len,
      max(char_length({field})) as f_max_len
    from `{schema}`.`{table}`

  field_stat_deep: |
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field,
      count(*) as tot_cnt,
      count({field}) as f_cnt,
      count(*) - count({field}) as f_null_cnt,
      round(100.0 * (count(*) - count({field})) / count(*),1) as f_null_prct,
      count(distinct {field}) as f_dstct_cnt,
      round(100.0 * count(distinct {field}) / count(*),1) as f_dstct_prct,
      count(*) - count(distinct {field}) as f_dup_cnt,
      min({field}) as f_min,
      max({field}) as f_max,
      min(char_length(cast({field} as text))) as f_min_len,
      max(char_length(cast({field} as text))) as f_max_len
    from `{schema}`.`{table}`

  distro_field: |
    with t1 as (
      select
        '{field}'::text as field,
        {field},
        count(*) cnt
      from `{schema}`.`{table}`
      group by {field}
      order by count(*) desc
    )
    , t2 as (
      select
        '{field}'::text as field,
        count(*) ttl_cnt
      from `{schema}`.`{table}`
    )
    select
      '{table}' as table_nm,
      t1.field,
      {field} as value,
      cnt,
      round(100.0 * cnt / ttl_cnt, 2) as prct
    from t1
    join t2
      on t1.field = t2.field
    order by cnt desc

  distro_field_group: |
    with t1 as (
      select
        '{field}'::text as field,
        {group_expr} as group_exp,
        {field},
        count(*) cnt
      from `{schema}`.`{table}`
      group by {field}, {group_expr}
      order by count(*) desc
    )
    , t2 as (
      select
        '{field}'::text as field,
        count(*) ttl_cnt
      from `{schema}`.`{table}`
    )
    select
      '{table}' as table_nm,
      t1.field,
      t1.group_exp,
      {field} as value,
      cnt,
      round(100.0 * cnt / ttl_cnt, 2) as prct
    from t1
    join t2
      on t1.field = t2.field
    order by cnt desc

  distro_field_date: |
    with t1 as (
        select
          '{field}'::text as field,
          extract(year from {field}) as year,
          extract(month from {field}) as month,
          count(*) cnt
        from `{schema}`.`{table}`
        group by extract(year from {field}), extract(month from {field})
        order by extract(year from {field}), extract(month from {field})
      )
      , t2 as (
        select '{field}'::text as field, count(*) ttl_cnt
        from `{schema}`.`{table}`
      )
      select
        '{schema}' as schema_nm,
        '{table}' as table_nm,
        t1.field,
        t1.year,
        t1.month,
        cnt,
        round(100.0 * cnt / ttl_cnt, 2) as prct
      from t1
      join t2
        on t1.field = t2.field
      order by t1.year, t1.month

function:
  truncate_f: round({field}, 2, 1)
  truncate_datef: CONVERT(DATETIME, CONVERT(DATE, {field}))
  checksum_string: char_length({field})
  checksum_datetime: to_unix_timestamp64_nano(toDateTime64({field}, 6)) / 1000
  checksum_decimal: ABS(CAST({field} as nullable(int64)))

variable:
  # bind_string: "@p{c}"
  batch_rows: 200
  batch_values: 2000
  bool_as: string
  error_filter_table_exists: already
  quote_char: "`"
  timestamp_layout: "2006-01-02 15:04:05.000000 -07"
  timestamp_layout_str: to_time('{value}')
